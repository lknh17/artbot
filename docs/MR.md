# MR（变更记录 / 讨论记录）

> 目的：把关键决策、讨论结论、调用次数优化策略记录下来，方便回溯与对齐。

## 2026-03-01｜选题+发文调用次数优化（对话纪要）

### 背景
- 用户观察到：一次「选题 + 生成并推送一篇文章」看起来触发了约 8 次“大模型接口调用”。
- 实际拆解：通常是 **选题阶段多次文本LLM + 正文1次文本LLM + 生图(混元3.0)多次**。
- 诉求：
  1) 题库发散/扩充应当是“定期 1 次”，而不是每次选题都发散；
  2) 当天只需要生成 3 个具体标题（一次调用即可）；
  3) 正文 1 次固定；生图 3 次走混元3.0，但不应被误认为调用了 OpenClaw agent 的模型。

### 结论与改造方向
1. **选题阶段：改为单次生成候选标题（1 call / account / run）**
   - 取消「按热点逐条 rewrite」导致的 N 次调用。
   - 取消「题库即时发散」导致的额外调用（改为模板/题库抽样）。

2. **题库：新增周期扩充脚本（一次调用生成 N 条）**
   - 新增脚本：`scripts/topic_bank_expand.py`
   - 用途：周更/日更选题库标题池，日常选题不再为“发散标题”消耗 LLM 调用。

3. **指标拆分：文本LLM vs 图像模型**
   - 在 `pipeline_debug.json` 增加 metrics：`llm_image_calls` / `llm_image_provider`。
   - 在文本 LLM 中间层增加 metrics：`llm_text_calls` / `llm_backend`，并注入到 pipeline debug。

### 预期效果
- 日常「选题」阶段文本调用次数：从热点逐条 rewrite 的 N 次 → **1 次/账号**。
- 「发一篇」阶段文本调用次数：正文 **1 次**。
- 生图调用：仍为混元 3.0 的 **3 次**，但日志/指标将与文本调用分开统计。
